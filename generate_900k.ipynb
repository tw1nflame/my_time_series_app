{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6059f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1461 rows from 'train_data.xlsx'.\n",
      "Generating data to reach 900000 rows, preserving original shop-location combinations and spreading over 5 future years...\n",
      "Saving expanded data (900000 rows) to 'train_data_900k.xlsx'...\n",
      "Successfully expanded the table with original shop-location combinations and saved to 'train_data_900k.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Specify the name of your input Excel file\n",
    "input_filename = 'train_data.xlsx' # <--- Updated to your filename\n",
    "# Specify the name for the output Excel file\n",
    "output_filename = 'train_data_900k.xlsx'\n",
    "# Specify the target number of rows\n",
    "target_num_rows = 900000\n",
    "# Specify the duration in years for generating future dates\n",
    "# Data will be spread across this many years starting from the day after the last original date.\n",
    "# Increase this value if you want fewer entries per future day, or decrease for more.\n",
    "future_years_to_generate = 5 # <--- You can adjust this value\n",
    "\n",
    "# Assumed column names based on the likely header row and your previous error.\n",
    "# If your actual header row has different names, update these strings.\n",
    "date_col = 'Date'\n",
    "country_col = 'Country'\n",
    "city_col = 'City'\n",
    "shop_col = 'Shop'\n",
    "target_col = 'Target'\n",
    "\n",
    "# List of columns for location combinations\n",
    "location_cols = [country_col, city_col, shop_col]\n",
    "\n",
    "# --- Data Processing ---\n",
    "try:\n",
    "    # Read the original Excel file - assuming it has a header row now\n",
    "    df_original = pd.read_excel(input_filename)\n",
    "\n",
    "    # --- Validate Columns ---\n",
    "    # Check if the expected columns are present after reading with header\n",
    "    required_cols = [date_col, country_col, city_col, shop_col, target_col]\n",
    "    if not all(col in df_original.columns for col in required_cols):\n",
    "        missing = [col for col in required_cols if col not in df_original.columns]\n",
    "        raise KeyError(f\"The following required columns were not found in the Excel file based on the header: {missing}. Please check the '{required_cols}' list in the script and the header row of your file.\")\n",
    "\n",
    "    # Get the current number of rows (excluding header)\n",
    "    current_num_rows = len(df_original)\n",
    "\n",
    "    if current_num_rows == 0:\n",
    "        print(f\"Error: The file '{input_filename}' is empty or contains no data after reading the header.\")\n",
    "    elif current_num_rows >= target_num_rows:\n",
    "        print(f\"The original file already contains {current_num_rows} rows, which is equal to or more than the target ({target_num_rows}). No expansion needed.\")\n",
    "        # Optionally save the original file to the output name if it meets the criteria\n",
    "        # df_original.to_excel(output_filename, index=False)\n",
    "    else:\n",
    "        print(f\"Read {current_num_rows} rows from '{input_filename}'.\")\n",
    "        print(f\"Generating data to reach {target_num_rows} rows, preserving original shop-location combinations and spreading over {future_years_to_generate} future years...\")\n",
    "\n",
    "        # Convert the 'Date' column to datetime objects\n",
    "        df_original[date_col] = pd.to_datetime(df_original[date_col])\n",
    "\n",
    "        # Find the last date in the original data\n",
    "        last_date = df_original[date_col].max()\n",
    "\n",
    "        # Calculate the number of rows to generate\n",
    "        num_rows_to_generate = target_num_rows - current_num_rows\n",
    "\n",
    "        # --- Generate New Data ---\n",
    "\n",
    "        # 1. Generate Dates: Create a pool of dates for the specified number of future years\n",
    "        start_date_for_generation = last_date + timedelta(days=1)\n",
    "        end_date_for_generation = start_date_for_generation + timedelta(days=int(future_years_to_generate * 365.25)) # Approx days in future years\n",
    "\n",
    "        # Generate all dates within this range\n",
    "        future_date_range = pd.date_range(start=start_date_for_generation, end=end_date_for_generation, freq='D')\n",
    "\n",
    "        # Convert to a list for easier cycling\n",
    "        future_date_pool = future_date_range.tolist()\n",
    "        num_dates_in_pool = len(future_date_pool)\n",
    "\n",
    "        if num_dates_in_pool == 0:\n",
    "             print(\"Error: Could not generate any dates in the specified future range. Check last date and future_years_to_generate.\")\n",
    "             exit()\n",
    "\n",
    "        # 2. Generate Country, City, Shop: Cycle through UNIQUE (Country, City, Shop) tuples\n",
    "        unique_shop_location_tuples = df_original[location_cols].drop_duplicates().values.tolist()\n",
    "        num_unique_combinations = len(unique_shop_location_tuples)\n",
    "\n",
    "        if num_unique_combinations == 0:\n",
    "             print(\"Error: Could not find any unique Country, City, Shop combinations in the original data.\")\n",
    "             exit()\n",
    "\n",
    "        new_shop_locations = []\n",
    "        new_dates = []\n",
    "        # Generate location and date pairs by cycling\n",
    "        for i in range(num_rows_to_generate):\n",
    "            location_index = i % num_unique_combinations\n",
    "            date_index = i % num_dates_in_pool\n",
    "\n",
    "            new_shop_locations.append(unique_shop_location_tuples[location_index])\n",
    "            new_dates.append(future_date_pool[date_index])\n",
    "\n",
    "\n",
    "        # Separate the new locations into lists for each column\n",
    "        new_countries = [loc[0] for loc in new_shop_locations]\n",
    "        new_cities = [loc[1] for loc in new_shop_locations]\n",
    "        new_shops = [loc[2] for loc in new_shop_locations]\n",
    "\n",
    "\n",
    "        # 3. Generate Target: Use statistics from the original data\n",
    "        mean_target = df_original[target_col].mean()\n",
    "        std_dev_target = df_original[target_col].std()\n",
    "\n",
    "        # Generate random values from a normal distribution\n",
    "        new_targets = np.random.normal(loc=mean_target, scale=std_dev_target, size=num_rows_to_generate)\n",
    "        new_targets = np.maximum(0, np.round(new_targets)).astype(int) # Round and clip negative values\n",
    "\n",
    "        # Create a new DataFrame with the generated data\n",
    "        df_generated = pd.DataFrame({\n",
    "            date_col: new_dates,\n",
    "            country_col: new_countries,\n",
    "            city_col: new_cities,\n",
    "            shop_col: new_shops,\n",
    "            target_col: new_targets\n",
    "        })\n",
    "\n",
    "        # Concatenate the original DataFrame and the generated DataFrame\n",
    "        df_expanded = pd.concat([df_original, df_generated], ignore_index=True)\n",
    "\n",
    "        # Ensure the total number of rows is exactly the target (safety check)\n",
    "        if len(df_expanded) > target_num_rows:\n",
    "             print(f\"Warning: Final row count ({len(df_expanded)}) exceeds target ({target_num_rows}). Truncating.\")\n",
    "             df_expanded = df_expanded.head(target_num_rows)\n",
    "        elif len(df_expanded) < target_num_rows:\n",
    "             print(f\"Warning: Final row count ({len(df_expanded)}) is less than target ({target_num_rows}). This is unexpected.\")\n",
    "\n",
    "\n",
    "        # Save the result to a new Excel file\n",
    "        print(f\"Saving expanded data ({len(df_expanded)} rows) to '{output_filename}'...\")\n",
    "        df_expanded.to_excel(output_filename, index=False)\n",
    "\n",
    "        print(f\"Successfully expanded the table with original shop-location combinations and saved to '{output_filename}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{input_filename}' was not found. Please ensure the file is in the same directory as the script, or provide the full path.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected column(s). {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28703603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 09:35:01,806\tINFO worker.py:1819 -- Started a local Ray instance.\n",
      "UserWarning: Parallel `read_excel` is a new feature! If you run into any problems, please visit https://github.com/modin-project/modin/issues. If you find a new issue and can't file it on GitHub, please email bug_reports@modin.org.\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "\n",
    "data = pd.read_excel('train_data_900k.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba24ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Country        City    Shop  Target\n",
      "0      2020-01-01  Canada     Toronto  Shop F     456\n",
      "1      2020-01-02  Canada   Vancouver  Shop H     476\n",
      "2      2020-01-03      UK  Manchester  Shop L     162\n",
      "3      2020-01-04  Canada   Vancouver  Shop H     307\n",
      "4      2020-01-05  Canada    Montreal  Shop I     262\n",
      "...           ...     ...         ...     ...     ...\n",
      "899995 2028-01-17  Canada     Toronto  Shop F     348\n",
      "899996 2028-01-18  Canada   Vancouver  Shop H     305\n",
      "899997 2028-01-19      UK  Manchester  Shop L     107\n",
      "899998 2028-01-20  Canada    Montreal  Shop I     112\n",
      "899999 2028-01-21     USA    New York  Shop A     168\n",
      "\n",
      "[900000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01294833",
   "metadata": {},
   "source": [
    "Installing collected packages: webencodings, sortedcontainers, fastjsonschema, zict, widgetsnbextension, websocket-client, webcolors, uri-template, types-python-dateutil, tomli, tinycss2, tblib, send2trash, rfc3986-validator, rfc3339-validator, pywinpty, python-json-logger, pycparser, pandocfilters, overrides, mistune, locket, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, httpcore, fqdn, dataframe-api-compat, bleach, babel, async-lru, terminado, partd, cffi, arrow, modin, jupyter-server-terminals, isoduration, ipywidgets, httpx, dask, argon2-cffi-bindings, nbformat, jupyter-console, distributed, argon2-cffi, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter, modin-spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41df792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Parallel `read_excel` is a new feature! If you run into any problems, please visit https://github.com/modin-project/modin/issues. If you find a new issue and can't file it on GitHub, please email bug_reports@modin.org.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('train_data_900k.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2c63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5dbc42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('train_data_900k.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
